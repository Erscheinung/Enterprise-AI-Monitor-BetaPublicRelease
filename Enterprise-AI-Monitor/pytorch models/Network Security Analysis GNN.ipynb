{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d08ff4cc-305b-4264-aeff-3dcec6291111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]\n",
      "Torch version: 2.5.1\n",
      "CUDA available? True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available?\", torch.cuda.is_available())\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17b54cf8-4e0f-4506-9e97-38a452e7a069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape: (175341, 42) y shape: (175341,)\n",
      "Test  X shape: (82332, 42) y shape: (82332,)\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "TRAIN_PATH = \"UNSW_NB15_training-set.csv\"\n",
    "TEST_PATH  = \"UNSW_NB15_testing-set.csv\"\n",
    "\n",
    "# Read CSVs\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# NaN in attack_cat\n",
    "train_df = train_df.assign(attack_cat=train_df['attack_cat'].fillna('Normal'))\n",
    "test_df = test_df.assign(attack_cat=test_df['attack_cat'].fillna('Normal'))\n",
    "\n",
    "# Encode 'attack_cat' as the label\n",
    "attack_cat_encoder = LabelEncoder()\n",
    "train_df['attack_cat'] = attack_cat_encoder.fit_transform(train_df['attack_cat'])\n",
    "test_df['attack_cat'] = attack_cat_encoder.transform(test_df['attack_cat'])\n",
    "\n",
    "# Handling cols better\n",
    "cat_cols = ['proto', 'service', 'state']\n",
    "for col in cat_cols:\n",
    "    # Get unique values from both train and test\n",
    "    combined_categories = pd.concat([train_df[col], test_df[col]]).unique()\n",
    "    le = LabelEncoder()\n",
    "    le.fit(combined_categories.astype(str))\n",
    "    \n",
    "    # Transform separately\n",
    "    train_df[col] = le.transform(train_df[col].astype(str))\n",
    "    test_df[col] = le.transform(test_df[col].astype(str))\n",
    "\n",
    "# Drop unused cols\n",
    "drop_cols = ['id', 'label']\n",
    "for c in drop_cols:\n",
    "    if c in train_df.columns:\n",
    "        train_df.drop(columns=c, inplace=True)\n",
    "    if c in test_df.columns:\n",
    "        test_df.drop(columns=c, inplace=True)\n",
    "\n",
    "feature_cols = [c for c in train_df.columns if c != 'attack_cat']\n",
    "X_train = train_df[feature_cols].values\n",
    "y_train = train_df['attack_cat'].values\n",
    "X_test = test_df[feature_cols].values\n",
    "y_test = test_df['attack_cat'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Train X shape:\", X_train.shape, \"y shape:\", y_train.shape)\n",
    "print(\"Test  X shape:\", X_test.shape,  \"y shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35cb7c4a-c357-4664-be8a-2f9680d64514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index shape: torch.Size([2, 752187])\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=k)\n",
    "knn.fit(X_train)\n",
    "# This gives us the indices of the neighbors\n",
    "neighbors = knn.kneighbors(X_train, return_distance=False)\n",
    "\n",
    "# Build edge list from the neighbors array\n",
    "edge_source = []\n",
    "edge_target = []\n",
    "for i in range(len(neighbors)):\n",
    "    for j in neighbors[i]:\n",
    "        # skip self-loops if you want\n",
    "        if i != j:\n",
    "            edge_source.append(i)\n",
    "            edge_target.append(j)\n",
    "\n",
    "edge_index = np.vstack((edge_source, edge_target))\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "print(\"edge_index shape:\", edge_index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0453f58a-83e2-47d0-91bd-1ffd251e30e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[175341, 42], edge_index=[2, 752187], y=[175341])\n",
      "Train data: #nodes = 175341 #edges = 752187 num_features = 42\n",
      "Data(x=[82332, 42], edge_index=[2, 343691], y=[82332])\n",
      "Test data: #nodes = 82332 #edges = 343691 num_features = 42\n"
     ]
    }
   ],
   "source": [
    "# Create the train data object\n",
    "x_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "train_data = Data(x=x_train_tensor, y=y_train_tensor, edge_index=edge_index)\n",
    "\n",
    "print(train_data)\n",
    "print(\"Train data: #nodes =\", train_data.num_nodes, \n",
    "      \"#edges =\", train_data.num_edges, \n",
    "      \"num_features =\", train_data.num_features)\n",
    "\n",
    "# For the test set, similarly create a separate graph:\n",
    "knn_test = NearestNeighbors(n_neighbors=k)\n",
    "knn_test.fit(X_test)\n",
    "neighbors_test = knn_test.kneighbors(X_test, return_distance=False)\n",
    "\n",
    "edge_source_test = []\n",
    "edge_target_test = []\n",
    "for i in range(len(neighbors_test)):\n",
    "    for j in neighbors_test[i]:\n",
    "        if i != j:\n",
    "            edge_source_test.append(i)\n",
    "            edge_target_test.append(j)\n",
    "\n",
    "edge_index_test = np.vstack((edge_source_test, edge_target_test))\n",
    "edge_index_test = torch.tensor(edge_index_test, dtype=torch.long)\n",
    "\n",
    "x_test_tensor = torch.tensor(X_test, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "test_data = Data(x=x_test_tensor, y=y_test_tensor, edge_index=edge_index_test)\n",
    "\n",
    "print(test_data)\n",
    "print(\"Test data: #nodes =\", test_data.num_nodes, \n",
    "      \"#edges =\", test_data.num_edges, \n",
    "      \"num_features =\", test_data.num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6363d4e-4e39-48b6-bb30-390943e11a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GCN(torch.nn.Module):\n",
    "#     def __init__(self, num_features, hidden_channels, num_classes):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "#         self.conv2 = GCNConv(hidden_channels, num_classes)\n",
    "        \n",
    "#     def forward(self, x, edge_index):\n",
    "#         # 1) First layer\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = F.relu(x)\n",
    "#         # 2) Second layer (logits)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         return x\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e06e73e2-adfd-4514-8040-9bba27bfad28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch: 01, Loss: 2.5330\n",
      "Epoch: 02, Loss: 1.7841\n",
      "Epoch: 03, Loss: 1.4590\n",
      "Epoch: 04, Loss: 1.2525\n",
      "Epoch: 05, Loss: 1.1291\n",
      "Epoch: 06, Loss: 1.0703\n",
      "Epoch: 07, Loss: 1.0292\n",
      "Epoch: 08, Loss: 0.9823\n",
      "Epoch: 09, Loss: 0.9447\n",
      "Epoch: 10, Loss: 0.9238\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Create model\n",
    "num_features = train_data.num_features\n",
    "num_classes = len(np.unique(y_train))  # number of distinct attack_cat classes\n",
    "hidden_channels = 64\n",
    "\n",
    "model = GCN(num_features, hidden_channels, num_classes).to(device)\n",
    "train_data = train_data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(train_data.x, train_data.edge_index)\n",
    "    loss = F.cross_entropy(out, train_data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(1, epochs+1):\n",
    "    loss_val = train()\n",
    "    print(f\"Epoch: {epoch:02d}, Loss: {loss_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44783374-befa-47bb-9984-09bdac45f598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5634\n"
     ]
    }
   ],
   "source": [
    "# Move test data to device\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(test_data.x, test_data.edge_index)\n",
    "    pred = logits.argmax(dim=1)\n",
    "    correct = (pred == test_data.y).sum()\n",
    "    acc = int(correct) / test_data.num_nodes\n",
    "\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
